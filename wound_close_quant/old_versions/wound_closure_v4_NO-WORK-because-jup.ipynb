{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2384efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n",
      "/Users/domchom/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/napari/_qt/qt_event_loop.py:284: FutureWarning: \n",
      "The 'gui_qt()' context manager is deprecated.\n",
      "If you are running napari from a script, please use 'napari.run()' as follows:\n",
      "\n",
      "    import napari\n",
      "\n",
      "    viewer = napari.Viewer()  # no prior setup needed\n",
      "    # other code using the viewer...\n",
      "    napari.run()\n",
      "\n",
      "In IPython or Jupyter, 'napari.run()' is not necessary. napari will automatically\n",
      "start an interactive event loop for you: \n",
      "\n",
      "    import napari\n",
      "    viewer = napari.Viewer()  # that's it!\n",
      "\n",
      "  warn(\n",
      "TiffPage 0: TypeError: read_bytes() missing 3 required positional arguments: 'dtype', 'count', and 'offsetsize'\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"'Shapes' is not in list\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/napari/utils/events/containers/_typed.py:140\u001b[0m, in \u001b[0;36mTypedMutableSequence.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex(key))\n\u001b[1;32m    141\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/napari/utils/events/containers/_typed.py:228\u001b[0m, in \u001b[0;36mTypedMutableSequence.index\u001b[0;34m(self, value, start, stop)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[39mreturn\u001b[39;00m i\n\u001b[0;32m--> 228\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    229\u001b[0m     trans\u001b[39m.\u001b[39m_(\n\u001b[1;32m    230\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m{value!r}\u001b[39;00m\u001b[39m is not in list\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m         deferred\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    232\u001b[0m         value\u001b[39m=\u001b[39mvalue,\n\u001b[1;32m    233\u001b[0m     )\n\u001b[1;32m    234\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: 'Shapes' is not in list",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m\n\u001b[1;32m     78\u001b[0m all_ellipse_coords \u001b[39m=\u001b[39m {}\n\u001b[1;32m     80\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m all_images:\n\u001b[1;32m     81\u001b[0m     \u001b[39m# Add image to viewer and wait for user to define ellipse\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     ellipse \u001b[39m=\u001b[39m user_define_ellipse(key)\n\u001b[1;32m     83\u001b[0m     \u001b[39mprint\u001b[39m(ellipse)\n\u001b[1;32m     85\u001b[0m     \u001b[39m# Save ellipse coordinates\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 72\u001b[0m, in \u001b[0;36muser_define_ellipse\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNo ellipse has been drawn yet\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m     napari\u001b[39m.\u001b[39mrun()\n\u001b[0;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m save_shape(viewer)\n",
      "Cell \u001b[0;32mIn[8], line 63\u001b[0m, in \u001b[0;36muser_define_ellipse.<locals>.save_shape\u001b[0;34m(viewer)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39m@viewer\u001b[39m\u001b[39m.\u001b[39mbind_key(\u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_shape\u001b[39m(viewer):\n\u001b[0;32m---> 63\u001b[0m     last_shape \u001b[39m=\u001b[39m viewer\u001b[39m.\u001b[39;49mlayers[\u001b[39m'\u001b[39;49m\u001b[39mShapes\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mdata[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     64\u001b[0m     \u001b[39mif\u001b[39;00m last_shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m         viewer\u001b[39m.\u001b[39mwindow\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/napari/utils/events/containers/_typed.py:142\u001b[0m, in \u001b[0;36mTypedMutableSequence.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex(key))\n\u001b[1;32m    141\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 142\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mstr\u001b[39m(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    144\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_list[key]\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__newlike__(result) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m result\n",
      "\u001b[0;31mKeyError\u001b[0m: \"'Shapes' is not in list\""
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import pyclesperanto_prototype as cle\n",
    "import tifffile\n",
    "import scipy \n",
    "import skimage\n",
    "import imageio.v2 as imageio\n",
    "import os \n",
    "import logging\n",
    "import napari\n",
    "\n",
    "#################################################\n",
    "#############   USER INPUTS   ###################\n",
    "#################################################\n",
    "\n",
    "num_lines = 180 #how many line scans per frame\n",
    "line_length = 150 #choose you line length\n",
    "bin_num = 150 #number of data points per line\n",
    "image_folder_path = '/Users/domchom/Documents/GitHub/Dom_python_scripts/wound_close_quant/movies' #path to movie of interest\n",
    "\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "#################################################\n",
    "\n",
    "\n",
    "def get_Images(folder_path):\n",
    "    ''' saves all images in a dict {filepath: img as np array}'''\n",
    "    all_images = {}\n",
    "    # Loop through all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if file is a TIF file\n",
    "        if filename.endswith('.tif'):\n",
    "            # Open the TIF file using gdal\n",
    "            filepath = os.path.join(folder_path, filename)\n",
    "\n",
    "            img = tifffile.imread(filepath)\n",
    "\n",
    "            # standardize image dimensions\n",
    "            with tifffile.TiffFile(filepath) as tif_file:\n",
    "                metadata = tif_file.imagej_metadata\n",
    "            num_channels = metadata.get('channels', 1)\n",
    "            num_slices = metadata.get('slices', 1)\n",
    "            num_frames = metadata.get('frames', 1)\n",
    "            img = img.reshape(num_frames, \n",
    "                            num_slices, \n",
    "                            num_channels, \n",
    "                            img.shape[-2], \n",
    "                            img.shape[-1])\n",
    "            \n",
    "            all_images[filepath] = img\n",
    "    \n",
    "    return all_images\n",
    "\n",
    "def user_define_ellipse(image_path):\n",
    "    # asking the user to identify the ring of interest\n",
    "    with napari.gui_qt():\n",
    "        viewer = napari.Viewer()\n",
    "        viewer.open(image_path)\n",
    "\n",
    "        @viewer.bind_key('s')\n",
    "        def save_shape(viewer):\n",
    "            last_shape = viewer.layers['Shapes'].data[-1]\n",
    "            if last_shape is not None:\n",
    "                viewer.window.close()\n",
    "                return last_shape\n",
    "            else:\n",
    "                print('No ellipse has been drawn yet')\n",
    "\n",
    "        napari.run()\n",
    "\n",
    "    return save_shape(viewer)\n",
    "    \n",
    "def get_center_and_ratio(shape):\n",
    "    # Define the rectangle's coordinates\n",
    "    x1, y1 = shape[0][3] , shape[0][2]\n",
    "    x2, y2 = shape[2][3] , shape[2][2]\n",
    "\n",
    "    # Calculate the center and ratio\n",
    "    center = [(x1 + x2) / 2, (y1 + y2) / 2]\n",
    "    ratio = abs(y2 - y1) / abs(x2 - x1)\n",
    "\n",
    "    return center, ratio\n",
    "\n",
    "\n",
    "def create_lines(center, ellipse_ratio):\n",
    "    # Define the two ellipses\n",
    "    small_ellipse_width = 20\n",
    "    small_ellipse_height = small_ellipse_width * ellipse_ratio\n",
    "    large_ellipse_width = line_length * 2 + small_ellipse_width\n",
    "    large_ellipse_height = line_length * 2 + small_ellipse_height\n",
    "\n",
    "    small_ellipse = Ellipse(xy=(center[0], center[1]), width=small_ellipse_width, height=small_ellipse_height, angle=0)\n",
    "    large_ellipse = Ellipse(xy=(center[0], center[1]), width=large_ellipse_width, height=large_ellipse_height, angle=0)\n",
    "\n",
    "    # Check if small ellipse is inside large ellipse\n",
    "    if large_ellipse.contains_point(small_ellipse.center):\n",
    "        \n",
    "        # Create an array of points on the large ellipse\n",
    "        theta = np.linspace(0, 2 * np.pi, num_lines + 1)\n",
    "        points = np.stack([large_ellipse.center[0] + large_ellipse.width/2*np.cos(theta), \n",
    "                        large_ellipse.center[1] + large_ellipse.height/2*np.sin(theta)], axis=1)\n",
    "\n",
    "        # Loop over each point on the large ellipse and calculate the shortest distance to the small ellipse and line segment\n",
    "        line_coords = [[np.linspace(x0, x1, bin_num), np.linspace(y0, y1, bin_num)] \n",
    "                    for i, point in enumerate(points) \n",
    "                    if (distance := np.linalg.norm(small_ellipse.center - point) - small_ellipse_width / 2) >= 0\n",
    "                    for theta in [np.arctan2(point[1] - large_ellipse.center[1], point[0] - large_ellipse.center[0])]\n",
    "                    for x0, y0, x1, y1 in [[small_ellipse.center[0] + small_ellipse_width / 2 * np.cos(theta), \n",
    "                                            small_ellipse.center[1] + small_ellipse_height / 2 * np.sin(theta), \n",
    "                                            point[0], point[1]]]]\n",
    "        \n",
    "    return line_coords\n",
    "\n",
    "\n",
    "def return_line_ref_figure(img, line_coords, center):\n",
    "        # Plot the ellipses and lines\n",
    "    fig, ax = plt.subplots()\n",
    "    for coords in line_coords:\n",
    "        ax.plot(coords[0], coords[1], 'k-', linewidth=0.5)\n",
    "    ax.plot(center[0], center[1], 'ro')\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.imshow(img)    \n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    return fig\n",
    "\n",
    "\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "#######################################################\n",
    "\n",
    "all_images = get_Images(image_folder_path)\n",
    "\n",
    "all_ellipse_coords = {}\n",
    "\n",
    "for key in all_images:\n",
    "    ellipse = user_define_ellipse(key)\n",
    "    center, ratio = get_center_and_ratio(ellipse)\n",
    "\n",
    "    all_ellipse_coords[key] = [center, ratio]\n",
    "\n",
    "for filename in all_images:\n",
    "    image = all_images[filename]\n",
    "    center, ratio = all_ellipse_coords[filename][0], all_ellipse_coords[filename][1]\n",
    "    line_coords =  create_lines(center, ratio)\n",
    "    return_line_ref_figure(image[14][0][0], line_coords, center)\n",
    "    \n",
    "    if not os.path.exists(\"reference_lines\"):\n",
    "        os.mkdir(\"reference_lines\")\n",
    "\n",
    "    fig = return_line_ref_figure(image[14][0][0], line_coords, center)\n",
    "    file_name = filename.split('.')[0]\n",
    "    file_name = f\"{file_name.split('/')[-1]}_ref.png\"\n",
    "    file_path = '/Users/domchom/Documents/GitHub/Dom_python_scripts/wound_close_quant/movies/reference_lines/' + file_name\n",
    "    plt.close()\n",
    "    fig.savefig(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca9836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-11 21:58:48,513 - INFO - Calculating channel 1, frame 1\n",
      "2023-03-11 21:58:49,490 - INFO - Calculating channel 1, frame 2\n",
      "2023-03-11 21:58:50,457 - INFO - Calculating channel 1, frame 3\n",
      "2023-03-11 21:58:51,397 - INFO - Calculating channel 1, frame 4\n",
      "2023-03-11 21:58:52,333 - INFO - Calculating channel 1, frame 5\n",
      "2023-03-11 21:58:53,268 - INFO - Calculating channel 1, frame 6\n",
      "2023-03-11 21:58:54,200 - INFO - Calculating channel 1, frame 7\n",
      "2023-03-11 21:58:55,131 - INFO - Calculating channel 1, frame 8\n",
      "2023-03-11 21:58:56,061 - INFO - Calculating channel 1, frame 9\n",
      "2023-03-11 21:58:56,998 - INFO - Calculating channel 1, frame 10\n",
      "2023-03-11 21:58:57,930 - INFO - Calculating channel 1, frame 11\n",
      "2023-03-11 21:58:58,856 - INFO - Calculating channel 1, frame 12\n",
      "2023-03-11 21:58:59,830 - INFO - Calculating channel 1, frame 13\n",
      "2023-03-11 21:59:00,793 - INFO - Calculating channel 1, frame 14\n",
      "2023-03-11 21:59:01,723 - INFO - Calculating channel 1, frame 15\n",
      "2023-03-11 21:59:02,672 - INFO - Calculating channel 1, frame 16\n",
      "2023-03-11 21:59:03,620 - INFO - Calculating channel 1, frame 17\n",
      "2023-03-11 21:59:04,552 - INFO - Calculating channel 1, frame 18\n",
      "2023-03-11 21:59:05,493 - INFO - Calculating channel 1, frame 19\n",
      "2023-03-11 21:59:06,422 - INFO - Calculating channel 1, frame 20\n",
      "2023-03-11 21:59:07,368 - INFO - Calculating channel 1, frame 21\n",
      "2023-03-11 21:59:08,320 - INFO - Calculating channel 1, frame 22\n",
      "2023-03-11 21:59:09,260 - INFO - Calculating channel 1, frame 23\n",
      "2023-03-11 21:59:10,191 - INFO - Calculating channel 1, frame 24\n",
      "2023-03-11 21:59:11,135 - INFO - Calculating channel 1, frame 25\n",
      "2023-03-11 21:59:12,085 - INFO - Calculating channel 1, frame 26\n",
      "2023-03-11 21:59:13,041 - INFO - Calculating channel 1, frame 27\n",
      "2023-03-11 21:59:13,990 - INFO - Calculating channel 1, frame 28\n",
      "2023-03-11 21:59:14,959 - INFO - Calculating channel 1, frame 29\n",
      "2023-03-11 21:59:15,914 - INFO - Calculating channel 1, frame 30\n",
      "2023-03-11 21:59:16,864 - INFO - Calculating channel 1, frame 31\n",
      "2023-03-11 21:59:17,814 - INFO - Calculating channel 1, frame 32\n",
      "2023-03-11 21:59:18,768 - INFO - Calculating channel 1, frame 33\n",
      "2023-03-11 21:59:19,721 - INFO - Calculating channel 1, frame 34\n",
      "2023-03-11 21:59:20,670 - INFO - Calculating channel 1, frame 35\n",
      "2023-03-11 21:59:21,613 - INFO - Calculating channel 1, frame 36\n",
      "2023-03-11 21:59:22,562 - INFO - Calculating channel 1, frame 37\n",
      "2023-03-11 21:59:23,513 - INFO - Calculating channel 1, frame 38\n",
      "2023-03-11 21:59:24,464 - INFO - Calculating channel 1, frame 39\n",
      "2023-03-11 21:59:25,394 - INFO - Calculating channel 1, frame 40\n",
      "2023-03-11 21:59:26,339 - INFO - Calculating channel 1, frame 41\n",
      "2023-03-11 21:59:27,273 - INFO - Calculating channel 1, frame 42\n",
      "2023-03-11 21:59:28,202 - INFO - Calculating channel 1, frame 43\n",
      "2023-03-11 21:59:29,128 - INFO - Calculating channel 1, frame 44\n",
      "2023-03-11 21:59:30,061 - INFO - Calculating channel 1, frame 45\n",
      "2023-03-11 21:59:31,011 - INFO - Calculating channel 1, frame 46\n",
      "2023-03-11 21:59:31,964 - INFO - Calculating channel 1, frame 47\n",
      "2023-03-11 21:59:32,912 - INFO - Calculating channel 1, frame 48\n",
      "2023-03-11 21:59:33,861 - INFO - Calculating channel 1, frame 49\n",
      "2023-03-11 21:59:34,803 - INFO - Calculating channel 1, frame 50\n",
      "2023-03-11 21:59:35,747 - INFO - Calculating channel 1, frame 51\n",
      "2023-03-11 21:59:36,690 - INFO - Calculating channel 2, frame 1\n",
      "2023-03-11 21:59:37,640 - INFO - Calculating channel 2, frame 2\n",
      "2023-03-11 21:59:38,588 - INFO - Calculating channel 2, frame 3\n",
      "2023-03-11 21:59:39,553 - INFO - Calculating channel 2, frame 4\n",
      "2023-03-11 21:59:40,489 - INFO - Calculating channel 2, frame 5\n",
      "2023-03-11 21:59:41,451 - INFO - Calculating channel 2, frame 6\n",
      "2023-03-11 21:59:42,440 - INFO - Calculating channel 2, frame 7\n",
      "2023-03-11 21:59:43,387 - INFO - Calculating channel 2, frame 8\n",
      "2023-03-11 21:59:44,337 - INFO - Calculating channel 2, frame 9\n",
      "2023-03-11 21:59:45,299 - INFO - Calculating channel 2, frame 10\n",
      "2023-03-11 21:59:46,265 - INFO - Calculating channel 2, frame 11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m     axes[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mplot(signal)\n\u001b[1;32m     49\u001b[0m     plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m---> 51\u001b[0m frames_list \u001b[39m=\u001b[39m calc_line_scans(img, num_frames, num_channels, line_coords)\n",
      "Cell \u001b[0;32mIn[88], line 31\u001b[0m, in \u001b[0;36mcalc_line_scans\u001b[0;34m(img, num_frames, num_channels, line_coords)\u001b[0m\n\u001b[1;32m     28\u001b[0m     y0, y1\u001b[39m=\u001b[39m y[\u001b[39m0\u001b[39m], y[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Extract the values along the line, using cubic interpolation\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     signal \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mndimage\u001b[39m.\u001b[39;49mmap_coordinates(img[f][\u001b[39m0\u001b[39;49m][c], np\u001b[39m.\u001b[39;49mvstack((x,y)))\n\u001b[1;32m     32\u001b[0m     signals_list\u001b[39m.\u001b[39mappend(signal)\n\u001b[1;32m     34\u001b[0m frames_list\u001b[39m.\u001b[39mappend(signals_list)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:453\u001b[0m, in \u001b[0;36mmap_coordinates\u001b[0;34m(input, coordinates, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[39mif\u001b[39;00m prefilter \u001b[39mand\u001b[39;00m order \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    452\u001b[0m     padded, npad \u001b[39m=\u001b[39m _prepad_for_spline_filter(\u001b[39minput\u001b[39m, mode, cval)\n\u001b[0;32m--> 453\u001b[0m     filtered \u001b[39m=\u001b[39m spline_filter(padded, order, output\u001b[39m=\u001b[39;49mnumpy\u001b[39m.\u001b[39;49mfloat64,\n\u001b[1;32m    454\u001b[0m                              mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    455\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     npad \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:191\u001b[0m, in \u001b[0;36mspline_filter\u001b[0;34m(input, order, output, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mif\u001b[39;00m order \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    190\u001b[0m     \u001b[39mfor\u001b[39;00m axis \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mndim):\n\u001b[0;32m--> 191\u001b[0m         spline_filter1d(\u001b[39minput\u001b[39;49m, order, axis, output\u001b[39m=\u001b[39;49moutput, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    192\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m output\n\u001b[1;32m    193\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/wound_close/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:132\u001b[0m, in \u001b[0;36mspline_filter1d\u001b[0;34m(input, order, axis, output, mode)\u001b[0m\n\u001b[1;32m    130\u001b[0m     mode \u001b[39m=\u001b[39m _ni_support\u001b[39m.\u001b[39m_extend_mode_to_code(mode)\n\u001b[1;32m    131\u001b[0m     axis \u001b[39m=\u001b[39m normalize_axis_index(axis, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mndim)\n\u001b[0;32m--> 132\u001b[0m     _nd_image\u001b[39m.\u001b[39;49mspline_filter1d(\u001b[39minput\u001b[39;49m, order, axis, output, mode)\n\u001b[1;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "#perform the line scans\n",
    "def calc_line_scans(img, num_frames, num_channels, line_coords):\n",
    "    \"\"\"\n",
    "    Calculates the signal along each line in each frame of an image stack.\n",
    "\n",
    "    Args:\n",
    "        img (ndarray): A 3D numpy array of shape (num_frames, num_channels, image_shape).\n",
    "        num_frames (int): The number of frames in the image stack.\n",
    "        num_channels (int): The number of channels in the image stack.\n",
    "        line_coords (list): A list of line coordinates, where each line is a list of x and y coordinates.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of frames, where each frame is a list of signals, where each signal is an array of signal values.\n",
    "    \"\"\"\n",
    "    frames_list = [] # store all the signals for every frame\n",
    "\n",
    "    for c in range(num_channels): #iterate over the channels\n",
    "        for f in range(num_frames): #iterate over the frames\n",
    "            signals_list = [] #lost to store the signal for each line for the frame\n",
    "            logging.info(f'Calculating channel {c+1}, frame {f+1}')\n",
    "\n",
    "            for line in line_coords: #create each line for each frame\n",
    "                x, y = line[0], line[1]\n",
    "                x0, x1 = x[0], x[-1]\n",
    "                y0, y1= y[0], y[-1]\n",
    "\n",
    "                # Extract the values along the line, using cubic interpolation\n",
    "                signal = scipy.ndimage.map_coordinates(img[f][0][c], np.vstack((x,y)))\n",
    "                signals_list.append(signal)\n",
    "\n",
    "            frames_list.append(signals_list)\n",
    "\n",
    "            #plot_idv_lines(signal,f,c,x0,x1,y0,y1)\n",
    "\n",
    "    logging.info(f'Finished calculating line scans for {num_frames} frames and {num_channels} channels')\n",
    "    return frames_list\n",
    "\n",
    "def plot_idv_lines(signal,f,c,x0,x1,y0,y1):\n",
    "    fig, axes = plt.subplots(nrows=2)\n",
    "    axes[0].imshow(img[f][0][c])\n",
    "    axes[0].plot([x0, x1], [y0, y1], 'r-')\n",
    "    axes[0].axis('image')\n",
    "\n",
    "    axes[1].plot(signal)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "frames_list = calc_line_scans(img, num_frames, num_channels, line_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd36bf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_array = np.array(frames_list)\n",
    "\n",
    "# Split the frames into two channels\n",
    "channel1_raw_values, channel2_raw_values = np.array_split(frames_array, 2)\n",
    "\n",
    "# Calculate the mean values for a channel\n",
    "def calculate_mean_values(channel):\n",
    "    '''\n",
    "    Iterates over each frame of a np array containing (num_frames, num_lines in frame, num_bins in line).\n",
    "    Averages each correspnding pixel on the line for each frame, and then returns a np\n",
    "    array that contains (num_frames, one line in frame, num_bins in line)\n",
    "    '''\n",
    "    bin_num = channel.shape[-1]\n",
    "    mean_values = []\n",
    "    for frame in channel:\n",
    "        pixel_avg_per_frame = []\n",
    "        for n in range(bin_num):\n",
    "            pixel_avg_per_frame.append(frame[:,n].mean())\n",
    "        mean_values.append(pixel_avg_per_frame)\n",
    "\n",
    "    return mean_values\n",
    "\n",
    "# Calculate the mean values for each channel\n",
    "raw_mean_values_Ch1 = calculate_mean_values(channel1_raw_values)\n",
    "raw_mean_values_Ch2 = calculate_mean_values(channel2_raw_values)\n",
    "\n",
    "# Combine the mean values for both channels into a single array\n",
    "mean_values_both_ch = np.array([raw_mean_values_Ch1, raw_mean_values_Ch2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdaba24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables for filter and normalization parameters\n",
    "window_length = 11 #for smoothing the line\n",
    "polyorder = 2 #for smoothing the line\n",
    "norm_min = 0 #set the min value for normalization\n",
    "norm_max = 1 #set the max value for normalization\n",
    "\n",
    "# Define a function to normalize the data for a channel\n",
    "def normalize_data(channel_raw_values):\n",
    "    norm_values = []\n",
    "    for signal in channel_raw_values:\n",
    "        signal_max = np.max(signal)\n",
    "        norm_signal = (signal / signal_max) * (norm_max - norm_min) + norm_min\n",
    "        norm_values.append(norm_signal)\n",
    "    return norm_values\n",
    "\n",
    "# Define a function to subtract background from the data for a channel\n",
    "def subtract_background(channel_raw_values, channel_ref_values):\n",
    "    bg_values = np.min(channel_ref_values)\n",
    "    norm_values = []\n",
    "    for signal in channel_raw_values:\n",
    "        signal_bg = (signal - bg_values) * (norm_max - norm_min) / (np.max(channel_ref_values) - bg_values)\n",
    "        norm_values.append(signal_bg)\n",
    "    return norm_values\n",
    "\n",
    "# Normalize the data for each channel\n",
    "norm_mean_values_Ch1 = normalize_data(raw_mean_values_Ch1)\n",
    "norm_mean_values_Ch2 = normalize_data(raw_mean_values_Ch2)\n",
    "\n",
    "# Subtract background from the data for each channel\n",
    "mean_values_Ch1_norm_bg = subtract_background(raw_mean_values_Ch1, raw_mean_values_Ch1)\n",
    "mean_values_Ch2_norm_bg = subtract_background(raw_mean_values_Ch2, raw_mean_values_Ch2)\n",
    "\n",
    "#define a function to smooth data\n",
    "def smooth_data(channel_values):\n",
    "    smoothed_data = []\n",
    "    for signal in channel_values:\n",
    "        signal_smooth = scipy.signal.savgol_filter(signal, window_length=window_length, polyorder=polyorder)\n",
    "        smoothed_data.append(signal_smooth)\n",
    "    return smoothed_data\n",
    "\n",
    "#smooth all data\n",
    "raw_values_Ch1_smooth = smooth_data(raw_mean_values_Ch1)\n",
    "raw_values_Ch2_smooth = smooth_data(raw_mean_values_Ch2)\n",
    "\n",
    "mean_values_both_ch_smooth = np.array([raw_values_Ch1_smooth, raw_values_Ch2_smooth])\n",
    "\n",
    "norm_mean_values_Ch1_smooth = smooth_data(norm_mean_values_Ch1)\n",
    "norm_mean_values_Ch2_smooth = smooth_data(norm_mean_values_Ch2)\n",
    "\n",
    "norm_mean_values_both_ch_smooth = np.array([norm_mean_values_Ch1_smooth, norm_mean_values_Ch2_smooth])\n",
    "\n",
    "mean_values_Ch1_norm_bg_smooth = smooth_data(mean_values_Ch1_norm_bg)\n",
    "mean_values_Ch2_norm_bg_smooth = smooth_data(mean_values_Ch2_norm_bg)\n",
    "\n",
    "mean_values_both_ch_bg_smooth= np.array([mean_values_Ch1_norm_bg_smooth, mean_values_Ch2_norm_bg_smooth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4a1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find peaks - will treat each frame like a box\n",
    "\n",
    "# make empty arrays to fill with peak measurements for each channel\n",
    "peak_widths = np.zeros(shape=(num_channels, num_frames))\n",
    "peak_maxs = np.zeros(shape=(num_channels, num_frames))\n",
    "peak_mins = np.zeros(shape=(num_channels, num_frames))\n",
    "\n",
    "# make a dictionary to store the arrays and measurments generated by this function so they don't have to be re-calculated later\n",
    "ind_peak_props = {}\n",
    "\n",
    "for channel in range(num_channels):\n",
    "    for frame_num in range(num_frames):\n",
    "\n",
    "        signal = scipy.signal.savgol_filter(mean_values_both_ch[channel][frame_num], window_length = 11, polyorder = 2)\n",
    "        peaks, _ = scipy.signal.find_peaks(signal, prominence=(np.max(signal)-np.min(signal))*0.65) #<--- edit last number to change the threshold\n",
    "\n",
    "        # if peaks detected, calculate properties and return property averages. Otherwise return nans\n",
    "        if len(peaks) > 0:\n",
    "            proms, _, _ = scipy.signal.peak_prominences(signal, peaks)\n",
    "            widths, heights, leftIndex, rightIndex = scipy.signal.peak_widths(signal, peaks, rel_height=0.5)\n",
    "            mean_width = np.mean(widths, axis=0)\n",
    "            mean_max = np.mean(signal[peaks], axis = 0)\n",
    "            mean_min = np.mean(signal[peaks]-proms, axis = 0)\n",
    "            peak_widths[channel, frame_num] = mean_width\n",
    "            peak_maxs[channel, frame_num] = mean_max\n",
    "            peak_mins[channel, frame_num] = mean_min\n",
    "\n",
    "            # store the smoothed signal, peak locations, maxs, mins, and widths for each box in each channel\n",
    "            ind_peak_props[f'Ch {channel} Box {frame_num}'] = {'smoothed': signal, \n",
    "                                                    'peaks': peaks,\n",
    "                                                    'proms': proms, \n",
    "                                                    'heights': heights, \n",
    "                                                    'leftIndex': leftIndex, \n",
    "                                                    'rightIndex': rightIndex}\n",
    "                \n",
    "        else:\n",
    "            peak_widths[channel, frame_num] = np.nan\n",
    "            peak_maxs[channel, frame_num] = np.nan\n",
    "            peak_mins[channel, frame_num] = np.nan\n",
    "\n",
    "            # store the smoothed signal, peak locations, maxs, mins, and widths for each box in each channel\n",
    "            # DC: might not acutally need this, as the code works fine without it (221222). Just putting for safety.\n",
    "            ind_peak_props[f'Ch {channel} Frame {frame_num}'] = {'smoothed': np.nan, \n",
    "                                                    'peaks': np.nan,\n",
    "                                                    'proms': np.nan, \n",
    "                                                    'heights': np.nan, \n",
    "                                                    'leftIndex': np.nan, \n",
    "                                                    'rightIndex': np.nan}\n",
    "\n",
    "peak_amps = peak_maxs - peak_mins\n",
    "peak_rel_amps = peak_amps / peak_mins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e31bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of unique channel combinations to calculate CCF for\n",
    "channels = list(range(num_channels))\n",
    "channel_combos = []\n",
    "for i in range(num_channels):\n",
    "    for j in channels[i+1:]:\n",
    "        channel_combos.append([channels[i],j])\n",
    "num_combos = len(channel_combos)\n",
    "\n",
    "# make empty arrays to populate with 1) period measurements and 2) acf curves   \n",
    "shifts = np.zeros(shape=(num_combos, num_frames))\n",
    "ccfs = np.zeros(shape=(num_combos, num_frames, bin_num*2-1))\n",
    "\n",
    "for combo_number, combo in enumerate(channel_combos):\n",
    "    for frame_num in range(num_frames):\n",
    "    \n",
    "        # calculate full cross-correlation\n",
    "        signal1 = mean_values_both_ch[0][frame_num]\n",
    "        signal2 = mean_values_both_ch[1][frame_num]\n",
    "\n",
    "        peaks1, _ = scipy.signal.find_peaks(signal1, prominence=(np.max(signal)-np.min(signal))*0.15) #<--- edit last number to change the threshold\n",
    "        peaks2, _ = scipy.signal.find_peaks(signal2, prominence=(np.max(signal)-np.min(signal))*0.15) #<--- edit last number to change the threshold\n",
    "\n",
    "        if len(peaks1) > 0 and len(peaks2) > 0:\n",
    "            corr_signal1 = signal1 - signal1.mean()\n",
    "            corr_signal2 = signal2 - signal2.mean()\n",
    "            cc_curve = np.correlate(corr_signal1, corr_signal2, mode='full')\n",
    "            # normalize the curve\n",
    "            cc_curve = scipy.signal.savgol_filter(cc_curve, window_length = 11, polyorder = 2)\n",
    "\n",
    "            cc_curve = cc_curve / (num_frames * signal1.std() * signal2.std())\n",
    "\n",
    "            peaks, _ = scipy.signal.find_peaks(cc_curve, prominence=0.01)\n",
    "            \n",
    "            # absolute difference between each peak and zero\n",
    "            peaks_abs = abs(peaks - cc_curve.shape[0]//2)\n",
    "            # if peaks were identified, pick the one closest to the center\n",
    "            if len(peaks) > 1:\n",
    "                delay = np.argmin(peaks_abs[np.nonzero(peaks_abs)])\n",
    "                delayIndex = peaks[delay]\n",
    "                delay_frames = delayIndex - cc_curve.shape[0]//2\n",
    "            # otherwise, return nans for both period and autocorrelation curve\n",
    "            else:\n",
    "                delay_frames = np.nan\n",
    "                cc_curve = np.full((bin_num*2-1), np.nan)\n",
    "        else:\n",
    "            delay_frames = np.nan\n",
    "            cc_curve = np.full((bin_num*2-1), np.nan)\n",
    "\n",
    "        shifts[combo_number, frame_num] = delay_frames\n",
    "        ccfs[combo_number, frame_num] = cc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d80954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_correlation(signal1, signal2, prominence):\n",
    "    peaks1, _ = scipy.signal.find_peaks(signal1, prominence=prominence)\n",
    "    peaks2, _ = scipy.signal.find_peaks(signal2, prominence=prominence)\n",
    "\n",
    "    if len(peaks1) > 0 and len(peaks2) > 0:\n",
    "        corr_signal1 = signal1 - signal1.mean()\n",
    "        corr_signal2 = signal2 - signal2.mean()\n",
    "        cc_curve = np.correlate(corr_signal1, corr_signal2, mode='full')\n",
    "        #smooth the curve\n",
    "        cc_curve = scipy.signal.savgol_filter(cc_curve, window_length=11, polyorder=2)\n",
    "        # normalize the curve\n",
    "        cc_curve = cc_curve / (num_frames * signal1.std() * signal2.std())\n",
    "        #find peaks\n",
    "        peaks, _ = scipy.signal.find_peaks(cc_curve, prominence=0.01)\n",
    "        # absolute difference between each peak and zero\n",
    "        peaks_abs = abs(peaks - cc_curve.shape[0] // 2)\n",
    "        # if peaks were identified, pick the one closest to the center\n",
    "        if len(peaks) > 1:\n",
    "            delay = np.argmin(peaks_abs[np.nonzero(peaks_abs)])\n",
    "            delayIndex = peaks[delay]\n",
    "            delay_frames = delayIndex - cc_curve.shape[0] // 2\n",
    "        # otherwise, return nans for both period and autocorrelation curve\n",
    "        else:\n",
    "            delay_frames = np.nan\n",
    "            cc_curve = np.full((bin_num * 2 - 1), np.nan)\n",
    "    else:\n",
    "        delay_frames = np.nan\n",
    "        cc_curve = np.full((bin_num * 2 - 1), np.nan)\n",
    "\n",
    "    return delay_frames, cc_curve\n",
    "\n",
    "# make a list of unique channel combinations to calculate CCF for\n",
    "channels = list(range(num_channels))\n",
    "channel_combos = []\n",
    "for i in range(num_channels):\n",
    "    for j in channels[i + 1:]:\n",
    "        channel_combos.append([channels[i], j])\n",
    "num_combos = len(channel_combos)\n",
    "\n",
    "for combo_number, combo in enumerate(channel_combos):\n",
    "    for frame_num in range(num_frames):\n",
    "        delay_frames, cc_curve = cross_correlation(mean_values_both_ch_smooth[0][frame_num], mean_values_both_ch_smooth[1][frame_num], (np.max(signal)-np.min(signal))*0.20)\n",
    "        shifts[combo_number, frame_num] = delay_frames\n",
    "        ccfs[combo_number, frame_num] = cc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206d44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_figure(ch1: np.ndarray, ch2: np.ndarray, ccf_curve: np.ndarray, ch1_name: str, ch2_name: str, shift: int):\n",
    "    '''\n",
    "    Space saving function to generate individual plots with variable input. returns a figure object.\n",
    "    '''\n",
    "    plt.style.use('dark_background')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    ax1.plot(ch1, color = 'tab:cyan', label = ch1_name)\n",
    "    ax1.plot(ch2, color = 'tab:red', label = ch2_name)\n",
    "    ax1.set_xlabel('distance (pixels)')\n",
    "    ax1.set_ylabel('Mean box px value')\n",
    "    ax1.legend(loc='upper right', fontsize = 'small', ncol = 1)\n",
    "    ax2.plot(np.arange(-line_length + 1, line_length ), ccf_curve)\n",
    "    ax2.set_ylabel('Crosscorrelation')\n",
    "    \n",
    "    if not shift == np.nan:\n",
    "        color = 'red'\n",
    "        ax2.axvline(x = shift, alpha = 0.5, c = color, linestyle = '--')\n",
    "        if shift < 1:\n",
    "            ax2.set_xlabel(f'{ch1_name} leads by {int(abs(shift))} pixels')\n",
    "        elif shift > 1:\n",
    "            ax2.set_xlabel(f'{ch2_name} leads by {int(abs(shift))} pixels')\n",
    "        else:\n",
    "            ax2.set_xlabel('no shift detected')\n",
    "    else:\n",
    "        ax2.set_xlabel(f'No peaks identified')\n",
    "    \n",
    "    fig.subplots_adjust(hspace=0.5)\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Create a new directory to store the figures\n",
    "if not os.path.exists(\"idv_frame_scans\"):\n",
    "    os.mkdir(\"idv_frame_scans\")\n",
    "\n",
    "for frame in range(num_frames):\n",
    "    fig = return_figure(mean_values_both_ch_smooth[0][frame], mean_values_both_ch_smooth[1][frame], ccfs[0][frame], \"rGBD\", \"wGBD\", shifts[0][frame])\n",
    "    file_name = f\"idv_frame_scan_{frame + 1}.png\"\n",
    "    file_path = os.path.join(\"idv_frame_scans\", file_name)\n",
    "    plt. close()\n",
    "    fig.savefig(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a93143d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yz/4g9pqy712zjbchs7r8hrj1rw0000gn/T/ipykernel_13359/3601154240.py:32: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(f'linescan_plots/frame_{i:04d}.png')\n",
      "/var/folders/yz/4g9pqy712zjbchs7r8hrj1rw0000gn/T/ipykernel_13359/3601154240.py:32: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(f'linescan_plots/frame_{i:04d}.png')\n",
      "/var/folders/yz/4g9pqy712zjbchs7r8hrj1rw0000gn/T/ipykernel_13359/3601154240.py:32: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(f'linescan_plots/frame_{i:04d}.png')\n"
     ]
    }
   ],
   "source": [
    "# Define function to create a linescan plot for a single frame\n",
    "def create_linescan_plot(frame, ch1, ch2, y_max, smooth = None):\n",
    "    plt.style.use('dark_background')\n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    ax1.set_ylim([0, y_max])\n",
    "\n",
    "    if smooth == True:\n",
    "        signal1 = scipy.signal.savgol_filter(ch1[frame], window_length=11, polyorder=2)\n",
    "        signal2 = scipy.signal.savgol_filter(ch2[frame], window_length=11, polyorder=2)\n",
    "    else:\n",
    "        signal1 = ch1[frame]\n",
    "        signal2 = ch2[frame]\n",
    "\n",
    "    ax1.plot(signal1, color='cyan', label='Ch1')\n",
    "    ax1.plot(signal2, color='red', label='Ch2')\n",
    "    plt.legend(loc='upper right', fontsize='small', ncol=2)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Define function to create linescan movie\n",
    "def create_linescan_movie(ch1, ch2, filename, smooth = None):\n",
    "    y_max = np.max(np.maximum(ch1, ch2))\n",
    "    if not os.path.exists('linescan_plots'):\n",
    "        os.mkdir('linescan_plots')\n",
    "    for i in range(len(ch1)):\n",
    "        fig = create_linescan_plot(i, ch1, ch2, y_max, smooth)\n",
    "        plt.savefig(f'linescan_plots/frame_{i:04d}.png')\n",
    "        plt.close(fig)\n",
    "    with imageio.get_writer(f'{filename}.mp4', mode='I') as writer:\n",
    "        for i in range(ch1.shape[0]):\n",
    "            image = imageio.imread(f'linescan_plots/frame_{i:04d}.png')\n",
    "            writer.append_data(image)\n",
    "    for filename in os.listdir('linescan_plots'):\n",
    "        os.remove(os.path.join('linescan_plots', filename))\n",
    "    os.rmdir('linescan_plots')\n",
    "\n",
    "create_linescan_movie(mean_values_both_ch_smooth[0], mean_values_both_ch_smooth[1], 'linescan_movie_raw', False)\n",
    "create_linescan_movie(mean_values_both_ch_bg_smooth[0], mean_values_both_ch_bg_smooth[1], 'linescan_movie_norm_bg', True)\n",
    "create_linescan_movie(norm_mean_values_both_ch_smooth[0], norm_mean_values_both_ch_smooth[1], 'linescan_movie_norm', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859612d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9e7c5e355466f7aa2375f2a09663ffde6f6d12fe8bf8f1a4007efb595e6d1812"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
